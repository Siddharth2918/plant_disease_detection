{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "# List of directories present in the dataset\n",
    "\n",
    "print(os.listdir('dataset/train/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diseased\n",
      "healthy\n",
      "1709\n",
      "1709\n"
     ]
    }
   ],
   "source": [
    "'''Loading x i.e. images and y i.e. labels from the dataset'''\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for dir_path in glob.glob(\"dataset/train/*\"):\n",
    "    label = dir_path.split('\\\\')[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(dir_path, '*.jpg')):\n",
    "        # print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# LabelEncodeing Labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336003072, 5)\n"
     ]
    }
   ],
   "source": [
    "def feature_extractor(dataset):\n",
    "    img_dataset = pd.DataFrame()\n",
    "    for image in range(dataset.shape[0]):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        input_img = dataset[image, :, :, :] # image , size, size, channels\n",
    "        img = input_img\n",
    "        # feature 1 - pixel values\n",
    "        pixel_values = img.reshape(-1)\n",
    "        df['pixel_value'] = pixel_values\n",
    "\n",
    "        # feature 2 - gabor filter\n",
    "        num = 1\n",
    "        kernels = []\n",
    "        for theta in range(2):\n",
    "            theta = theta / 4. * np.pi\n",
    "            for sigma in (1, 3):\n",
    "                lamda = np.pi/4\n",
    "                gamma = 0.5\n",
    "                gabor_label = 'Gabor' + str(num)\n",
    "                ksize=9 #kernel size\n",
    "                kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma)\n",
    "                kernels.append(kernel)\n",
    "                fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "                filtered_image = fimg.reshape(-1)\n",
    "                df[gabor_label] = filtered_image\n",
    "                num+=1\n",
    "\n",
    "        img_dataset = pd.concat([img_dataset, df], ignore_index=True)\n",
    "    return img_dataset\n",
    "\n",
    "image_features = feature_extractor(images)\n",
    "print(image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = np.expand_dims(image_features, axis=0)\n",
    "x = np.reshape(image_features, (images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Logistic Regression : 0.9093567251461988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "print(\"Accuracy from Logistic Regression : \" + str(lr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1\n",
      " 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0\n",
      " 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 0 0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "dtc_pred = dtc.predict(x_test)\n",
    "print(dtc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Decision Tree Classifier : 0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "dtc_acc = accuracy_score(y_test, dtc_pred)\n",
    "print(\"Accuracy from Decision Tree Classifier : \" + str(dtc_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Random Forest Classifier : 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
    "print(\"Accuracy from Random Forest Classifier : \" + str(rfc_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Gaussian Naive Bayes : 0.7134502923976608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb_pred = gnb.predict(x_test)\n",
    "gnb_acc = accuracy_score(y_test, gnb_pred)\n",
    "print(\"Accuracy from Gaussian Naive Bayes : \" + str(gnb_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from K Nearest Neighbours Classifier : 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "print(\"Accuracy from K Nearest Neighbours Classifier : \" + str(knn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Support Vector Classifier : 0.8918128654970761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc = accuracy_score(y_test, svc_pred)\n",
    "print(\"Accuracy from Support Vector Classifier : \" + str(svc_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Perceptron : 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "p = Perceptron()\n",
    "p.fit(x_train, y_train)\n",
    "p_pred= p.predict(x_test)\n",
    "p_acc = accuracy_score(y_test, p_pred)\n",
    "print(\"Accuracy from Perceptron : \" + str(p_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79239766 0.81871345 0.92397661 0.9122807  0.88856305]\n",
      "0.8671862941812009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()\n",
    "kf = KFold(n_splits=5)\n",
    "score = cross_val_score(logReg, x, y, cv=kf)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
